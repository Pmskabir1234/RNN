{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyO6WKgZB8xC0hwQ2FJM+i5P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pmskabir1234/RNN/blob/main/RNN_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7oPyfGDj43Xn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "np.random.seed(42)\n",
        "n_days = 365  # one year\n",
        "dates = pd.date_range(\"2024-01-01\", periods=n_days)\n",
        "\n",
        "# Base sinusoidal seasonal pattern for temperature\n",
        "t_base = 20 + 10 * np.sin(2 * np.pi * np.arange(n_days) / 365)  # seasonal pattern\n",
        "\n",
        "# Random weather variation\n",
        "daily_noise = np.random.normal(0, 1.5, n_days)\n",
        "t_max = t_base + daily_noise\n",
        "\n",
        "# t_min a bit lower but correlated\n",
        "t_min = t_max - np.random.uniform(5, 10, n_days)\n",
        "\n",
        "# Simulate rain (more rain in lower temperatures, because why not?)\n",
        "rain_prob = np.clip(1 - (t_max - 10) / 20, 0, 1)\n",
        "rain = np.random.binomial(1, rain_prob) * np.random.uniform(0, 20, n_days)\n",
        "\n",
        "# Correlate tomorrow's t_max (slight autocorrelation + random noise)\n",
        "tmax_tomorrow = np.roll(t_max, -1)\n",
        "tmax_tomorrow[-1] = tmax_tomorrow[-2]  # last value has no tomorrow\n",
        "\n",
        "# Add the cooling effect of rain to tomorrowâ€™s temp (mild)\n",
        "tmax_tomorrow = tmax_tomorrow - 0.3 * (rain > 5)\n",
        "\n",
        "# Build DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"date\": dates,\n",
        "    \"t_max\": np.round(t_max, 2),\n",
        "    \"t_min\": np.round(t_min, 2),\n",
        "    \"rain\": np.round(rain, 2),\n",
        "    \"tmax_tomorrow\": np.round(tmax_tomorrow, 2)\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "#initializing the weight metrices\n",
        "i_weights = np.random.rand(1,2)\n",
        "h_weights = np.random.rand(2,2)\n",
        "o_weights = np.random.rand(2,1)\n",
        "\n",
        "temps = df['t_max'].tail(3).to_numpy()\n",
        "\n",
        "x0 = temps[0].reshape(1,1)\n",
        "x1 = temps[1].reshape(1,1)\n",
        "x2 = temps[2].reshape(1,1)"
      ],
      "metadata": {
        "id": "A0qaZfVU4_AJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will make a forward pass, will check the outputs on the function ReLu"
      ],
      "metadata": {
        "id": "137iXVApOURs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for the first input x0\n",
        "xi_0 = x0 @ i_weights\n",
        "xh_0 = np.maximum(0,xi_0)     # basically applying ReLu as an activation function\n",
        "xo_0 = xh_0 @ o_weights\n",
        "\n",
        "#for the second input x1\n",
        "xi_1 = x1 @ i_weights\n",
        "xh_1 = np.maximum(0,xh_0+xi_1)\n",
        "xo_1 = xh_1 @ o_weights\n",
        "\n",
        "#for the third input x2\n",
        "xi_2 = x2 @ i_weights\n",
        "xh_2 = np.maximum(0,xh_1+xi_2)\n",
        "xo_2 = xh_2 @ o_weights\n",
        "\n",
        "print(xo_0,\"\\n\",xo_1,\"\\n\",xo_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSRI_hSVOe1c",
        "outputId": "7aac976f-ecc2-4f9f-ad50-fd0b879d4254"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16.96180733]] \n",
            " [[34.74887858]] \n",
            " [[53.06271403]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS we can see in the upper code, using the ReLu activation is quite good, simce the output is increasing all the way.\n",
        "Now, we will be making a full forward pass using tanh activation."
      ],
      "metadata": {
        "id": "eyigdoYUOwRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#weight and bias initialization\n",
        "np.random.seed(0)\n",
        "i_weight = np.random.rand(1,5)/5 - .1\n",
        "h_weight = np.random.rand(5,5)/5 - .1\n",
        "h_bias = np.random.rand(1,5)/5 - .1\n",
        "o_weight = np.random.rand(5,1)*50\n",
        "o_bias = np.random.rand(1,1)\n",
        "\n",
        "outputs = np.zeros(3)\n",
        "hiddens = np.zeros((3,5))\n",
        "prev_hidden = None\n",
        "sequence = df['t_max'].tail(3).to_numpy()"
      ],
      "metadata": {
        "id": "MTo1xdp7PMBW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will be making a full forward pass for the last three elements"
      ],
      "metadata": {
        "id": "omA_pE2l0hYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  x = sequence[i].reshape(1,1)\n",
        "  xi = x @ i_weight\n",
        "  if prev_hidden is None:\n",
        "    xh = xi\n",
        "  else:\n",
        "    xh = xi + prev_hidden @ h_weight + h_bias\n",
        "  xh = np.tanh(xh)\n",
        "  prev_hidden = xh\n",
        "  xo = xh @ o_weight + o_bias\n",
        "\n",
        "  hiddens[i] = xh\n",
        "  outputs[i] = xo\n",
        "\n",
        "print(hiddens,\"\\n\",outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_CEOhDB0g5D",
        "outputId": "39650141-46dd-4f61-93ee-f9e2de12cc4d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.18641004  0.68127617  0.37744574  0.17171052 -0.28672832]\n",
            " [ 0.17142784  0.72727201  0.40514684  0.29150329 -0.42080554]\n",
            " [ 0.18453064  0.74572762  0.40579821  0.30570107 -0.4351531 ]] \n",
            " [36.93716219 39.81854676 40.98894063]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2499244569.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  outputs[i] = xo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to reduce the training errors, we have to update\n",
        "our parameters. So we need to make backward pass."
      ],
      "metadata": {
        "id": "5SYFtv8N10ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(actual,predicted):\n",
        "  return np.mean((actual-predicted)**2)\n",
        "\n",
        "def mse_grad(actual,predicted):\n",
        "  return (predicted-actual)"
      ],
      "metadata": {
        "id": "Yix3g7QU2Dyz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actuals = df['tmax_tomorrow'].tail(3).to_numpy()\n",
        "\n",
        "loss_grad = mse_grad(actuals,outputs)\n",
        "loss_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZZQcyRd4tPS",
        "outputId": "120df935-e4a8-4c50-825b-13e918369fcd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16.67716219, 18.95854676, 20.42894063])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_hidden = None\n",
        "o_weight_grad, o_bias_grad, h_weight_grad, h_bias_grad, i_weight_grad = [0] * 5\n",
        "\n",
        "for i in range(2,-1,-1):\n",
        "  l_grad = loss_grad[i].reshape(1,1)\n",
        "  o_weight_grad += hiddens[i][:,np.newaxis] @ l_grad\n",
        "  o_bias_grad += np.mean(l_grad)\n",
        "\n",
        "  o_grad = l_grad @ o_weight.T\n",
        "\n",
        "  if next_hidden is None:\n",
        "    h_grad = o_grad\n",
        "  else:\n",
        "    h_grad = o_grad + next_hidden @ h_weight.T\n",
        "\n",
        "  tanh_deriv = 1 - hiddens[i,:][np.newaxis,:]\n",
        "  h_grad = np.multiply(h_grad, tanh_deriv)\n",
        "\n",
        "  next_hidden = h_grad\n",
        "\n",
        "  if i>0:\n",
        "    h_weight_grad  += hiddens[i-1,:][:,np.newaxis] @ h_grad\n",
        "    h_bias_grad += np.mean(l_grad)\n",
        "\n",
        "  i_weight_grad += sequence[i].reshape(1,1).T @ h_grad"
      ],
      "metadata": {
        "id": "Cthzs-GB7QXM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-6\n",
        "i_weight -= i_weight_grad * lr\n",
        "h_weight -= h_weight_grad * lr\n",
        "h_bias -= h_bias_grad * lr\n",
        "o_weight -= o_weight_grad * lr\n",
        "o_bias -= o_bias_grad * lr"
      ],
      "metadata": {
        "id": "S_qVJRZPFbqO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erKNuFCEF-hh",
        "outputId": "06cc0d97-d430-42a2-9ad3-cb9dbb5b082c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02155589,  0.03325866, -0.00229808, -0.03103546, -0.07013609]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "\n",
        "PREDICTORS = ['t_max','t_min','rain']\n",
        "TARGET = 'tmax_tomorrow'\n",
        "\n",
        "scaler = StandardScaler()\n",
        "split_data = (df.sample(frac=1),[int(.7*(len(df))),int(.85*(len(df)))])\n",
        "(X_train,y_train),(X_val,y_val),(X_test,y_test) = [[d[PREDICTORS].to_numpy(), d[[TARGET]].to_numpy()] for d in split_data]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "TF67WRRIGMfO",
        "outputId": "b9e03edf-9457-4c6a-c43d-4fc83a8710c6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-358254793.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msplit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.85\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPREDICTORS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
          ]
        }
      ]
    }
  ]
}